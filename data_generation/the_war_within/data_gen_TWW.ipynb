{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218072f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import re\n",
    "import joblib\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd492d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "STATIC_DIR = '../../static/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9d1ed",
   "metadata": {},
   "source": [
    "# Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5829cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpecializations(profession):\n",
    "    prof_data = dict()\n",
    "    \n",
    "    stats = ['skill', 'multicraft', 'resourcefulness', 'ingenuity']\n",
    "    for stat in stats:\n",
    "        prof_data[stat] = dict()\n",
    "        with open(DATA_DIR+profession.lower()+'_specializations_'+stat+'.csv', 'r') as file:\n",
    "            data = file.readlines()[1:]\n",
    "            for line in data:\n",
    "                line = line.strip().split(',')\n",
    "                node = line[0]\n",
    "                maxPoints = int(line[1])\n",
    "                gainPerPoint = int(line[2])\n",
    "                gains = line[3:][:maxPoints//5+1]\n",
    "                gains = [int(x) for x in gains]\n",
    "                    \n",
    "                prof_data[stat][node] = dict(zip(np.arange(start=0, stop=maxPoints+1, step=5), gains))\n",
    "                prof_data[stat][node]['scaling'] = gainPerPoint\n",
    "                \n",
    "    return prof_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5cec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItems(profession):\n",
    "    prof_items = dict()\n",
    "    \n",
    "    with open(DATA_DIR+profession+'_specializations_items.csv', 'r') as file:\n",
    "        data = file.readlines()[1:]\n",
    "        \n",
    "        for line in data:\n",
    "            line = line.strip().split(',')\n",
    "            itemID = int(line[0])\n",
    "            itemName = line[1]\n",
    "            \n",
    "            lastIndex = len(np.where(np.array(line)!='')[0])\n",
    "            nodes = line[2:lastIndex]\n",
    "            \n",
    "            prof_items[itemID] = dict()\n",
    "            prof_items[itemID]['itemName'] = itemName\n",
    "            prof_items[itemID]['nodes'] = nodes\n",
    "            \n",
    "    return prof_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a667c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeIcon(itemID):\n",
    "    url = f'https://www.wowhead.com/item={itemID}'\n",
    "    soup = BeautifulSoup(requests.get(url).text) \n",
    "    \n",
    "    #wowhead no longer has this href so need to us another method\n",
    "    #link = soup.find(name='link', attrs={'rel':'image_src'})['href'] \n",
    "    \n",
    "    #if link.find('http') < 0:\n",
    "    #    icon_links.append(None)\n",
    "    #    continue\n",
    "    #    \n",
    "    #first = link.find('http', 1)\n",
    "    #second = link.find('http', 2)\n",
    "    #if second >= first:\n",
    "    #    icon_links.append(link[second:])\n",
    "    #else:\n",
    "    #    assert('what')\n",
    "    \n",
    "    #new method using regex\n",
    "    \n",
    "    #string1 finds strings preceded by:   \"{itemID}:{\" \n",
    "    #and are also followed by:    ,\"screenshot\"\n",
    "    #the strings cannot include the symbol:   }\n",
    "    string1 = re.search(r'(?<=\"'+f'{itemID}'+r'\":{)[^}]+(?=,\"screenshot\")', str(soup)).group()\n",
    "    \n",
    "    #string2 searches string1 for strings preceded by:      \"icon\":\"\n",
    "    #and are also followed by:      \")\n",
    "    #that only contain a-z, A-Z, 0-9, _, and -\n",
    "    string2 = re.search(r'(?<=\"icon\":\")[\\w-]+(?=\")', string1).group()\n",
    "    site = 'https://wow.zamimg.com/images/wow/icons/large/'+string2+'.jpg'\n",
    "    \n",
    "    status_code = requests.get(site).status_code\n",
    "    \n",
    "    if status_code==200:\n",
    "        return {itemID: site}\n",
    "    else:\n",
    "        return {itemID: None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420c9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_id(old_id):\n",
    "    url = f'https://www.wowhead.com/item={old_id}?xml'\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, features='xml')\n",
    "    name = soup.find('name').text\n",
    "    text = soup.find('htmlTooltip').text\n",
    "    \n",
    "    #check for quality tier information\n",
    "    if text.find('quality-tier1') >= 0:\n",
    "        new_id = old_id+2\n",
    "        new_id_lower = old_id-2\n",
    "    elif text.find('quality-tier2') >= 0:\n",
    "        new_id = old_id+1\n",
    "        new_id_lower = old_id-1\n",
    "    else: #either its tier3 or it doesn't have tiers, in which use the old_id\n",
    "        return {old_id: old_id}\n",
    "    \n",
    "    \n",
    "    #wasn't a tier 3 item, so check the calculated id for if the name matches and is tier 3\n",
    "    #return the new id if it is the same name and tier 3, else return -1 for manual checking\n",
    "    try:\n",
    "        url = f'https://www.wowhead.com/item={new_id}?xml'\n",
    "        html = requests.get(url).text\n",
    "        soup = BeautifulSoup(html, features='xml')\n",
    "        if soup.find('name').text == name and soup.find('htmlTooltip').text.find('quality-tier3') >= 0:\n",
    "            return {old_id: new_id}\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        url = f'https://www.wowhead.com/item={new_id_lower}?xml'\n",
    "        html = requests.get(url).text\n",
    "        soup = BeautifulSoup(html, features='xml')\n",
    "        if soup.find('name').text == name and soup.find('htmlTooltip').text.find('quality-tier3') >= 0:\n",
    "            return {old_id: new_id_lower}\n",
    "    except:\n",
    "        return {old_id: -1}\n",
    "        \n",
    "    return {old_id: -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ec477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcomeQuality(skill, difficulty, tag):\n",
    "    if tag.lower()[:4]=='gear':\n",
    "        arr = np.array([1, 0.2*difficulty, 0.5*difficulty, 0.8*difficulty, difficulty])\n",
    "    else:\n",
    "        arr = np.array([1, 0.5*difficulty, difficulty])\n",
    "        \n",
    "    return (skill >= arr).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6aa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProfession(file, name):\n",
    "    #### deprecated version ###\n",
    "    prof = Profession(name)\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8-sig') as file:\n",
    "        data = file.readlines()\n",
    "        \n",
    "    reagentStart = 14 #column number where reagents start, since the variable counts dont work with headers\n",
    "    headers = data[0].strip().split(',')[:reagentStart] #no headers for reagents\n",
    "    for line in data[1:]:\n",
    "        itemInfo = line.strip().split(',')\n",
    "\n",
    "        try:\n",
    "            #take first index where an empty string occurs to indicate where input values stop\n",
    "            reagentEnd = np.where(np.array(itemInfo)=='')[0].min()\n",
    "        except:\n",
    "            #no value existed -> all indices are used -> use None for slicing\n",
    "            reagentEnd = None\n",
    "\n",
    "        reagents = itemInfo[reagentStart:reagentEnd]\n",
    "        reagents = np.array(reagents).astype(int)\n",
    "\n",
    "        itemInfo = dict(zip(headers, itemInfo[:reagentStart]))\n",
    "        reagents = dict(zip(reagents[::2], reagents[1::2]))\n",
    "\n",
    "        #can't call float('np.nan'), so replace the string with value manually\n",
    "        for k,v in itemInfo.items():\n",
    "            if v == 'np.nan':\n",
    "                itemInfo[k] = np.nan\n",
    "                \n",
    "        prof.add(itemName = itemInfo.get('itemName'),\n",
    "                 itemID = itemInfo.get('itemID'),\n",
    "                 reagents = reagents,\n",
    "                 crafterName = itemInfo.get('crafterName'),\n",
    "                 tag = itemInfo.get('tag'),\n",
    "                 difficulty = itemInfo.get('difficulty'),\n",
    "                 multicraft = itemInfo.get('multicraft'),\n",
    "                 quantity = itemInfo.get('quantity'),\n",
    "                 skill = itemInfo.get('skill'),\n",
    "                 rarity = itemInfo.get('rarity'),\n",
    "                 hasReagentQualities = (itemInfo.get('hasReagentQualities').title()=='True'),\n",
    "                 hasEmbellishmentSlot = (itemInfo.get('hasEmbellishmentSlot').title()=='True'),\n",
    "                 hasMissiveSlot = (itemInfo.get('hasMissiveSlot').title()=='True'),\n",
    "                 hasSafetyComponent = (itemInfo.get('hasSafetyComponent').title()=='True'),\n",
    "                 hasCrestSlot = (itemInfo.get('hasCrestSlot').title()=='True'))\n",
    "        \n",
    "    return prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2369f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProfession(file, name):\n",
    "    prof = Profession(name)\n",
    "    \n",
    "    baseFile = file[len(DATA_DIR):-4]\n",
    "    if baseFile[-1] in string.digits:\n",
    "        num = baseFile[-1]\n",
    "        baseFile = baseFile[:-1]\n",
    "    else:\n",
    "        num = ''\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8-sig') as file:\n",
    "        data = file.readlines()\n",
    "        \n",
    "    reagentStart = 14 #column number where reagents start, since the variable counts dont work with headers\n",
    "    headers = data[0].strip().split(',')[:reagentStart] #no headers for reagents\n",
    "    for line in data[1:]:\n",
    "        itemInfo = line.strip().split(',')\n",
    "\n",
    "        try:\n",
    "            #take first index where an empty string occurs to indicate where input values stop\n",
    "            reagentEnd = np.where(np.array(itemInfo)=='')[0].min()\n",
    "        except:\n",
    "            #no value existed -> all indices are used -> use None for slicing\n",
    "            reagentEnd = None\n",
    "\n",
    "        reagents = itemInfo[reagentStart:reagentEnd]\n",
    "        reagents = np.array(reagents).astype(int)\n",
    "\n",
    "        itemInfo = dict(zip(headers, itemInfo[:reagentStart]))\n",
    "        reagents = dict(zip(reagents[::2], reagents[1::2]))\n",
    "\n",
    "        #can't call float('np.nan'), so replace the string with value manually\n",
    "        for k,v in itemInfo.items():\n",
    "            if v == 'np.nan':\n",
    "                itemInfo[k] = np.nan\n",
    "                \n",
    "        itemID = int(itemInfo.get('itemID'))\n",
    "        \n",
    "        skill = float(itemInfo.get('skill'))\n",
    "        skill += float(baseStats.loc[baseStats['profession']==baseFile+num, 'level'].iloc[0])\n",
    "        skill += float(baseStats.loc[baseStats['profession']==baseFile+num, 'skill'].iloc[0])\n",
    "        \n",
    "        multicraft = float(itemInfo.get('multicraft'))\n",
    "        multicraft += float(baseStats.loc[baseStats['profession']==baseFile+num, 'multicraft'].iloc[0])\n",
    "        \n",
    "        if name.lower() != 'cooking':   \n",
    "            specializationInfo = getSpecializations(name.lower())\n",
    "            specializationItems = getItems(name.lower())\n",
    "            knowledgePoints = pd.read_csv(DATA_DIR+baseFile+'_knowledge'+num+'.csv')\n",
    "            \n",
    "            skill += getStat(specializationInfo['skill'], knowledgePoints, specializationItems[itemID]['nodes'])\n",
    "            multicraft += getStat(specializationInfo['multicraft'], knowledgePoints, \n",
    "                                  specializationItems[itemID]['nodes'])\n",
    "            \n",
    "        multicraft = np.round(multicraft/33, 1) #convert from stat to percent\n",
    "                \n",
    "        prof.add(itemName = itemInfo.get('itemName'),\n",
    "                 itemID = itemID,\n",
    "                 reagents = reagents,\n",
    "                 crafterName = itemInfo.get('crafterName'),\n",
    "                 tag = itemInfo.get('tag'),\n",
    "                 difficulty = itemInfo.get('difficulty'),\n",
    "                 multicraft = multicraft,\n",
    "                 quantity = itemInfo.get('quantity'),\n",
    "                 skill = skill,\n",
    "                 rarity = itemInfo.get('rarity'),\n",
    "                 hasReagentQualities = (itemInfo.get('hasReagentQualities').title()=='True'),\n",
    "                 hasEmbellishmentSlot = (itemInfo.get('hasEmbellishmentSlot').title()=='True'),\n",
    "                 hasMissiveSlot = (itemInfo.get('hasMissiveSlot').title()=='True'),\n",
    "                 hasSafetyComponent = (itemInfo.get('hasSafetyComponent').title()=='True'),\n",
    "                 hasCrestSlot = (itemInfo.get('hasCrestSlot').title()=='True'))\n",
    "        \n",
    "    return prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c4e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStat(nodeValues, knowledgePoints, nodes):    \n",
    "    statValue = 0\n",
    "    \n",
    "    for node in nodes:\n",
    "        try:\n",
    "            \n",
    "            knowledge = knowledgePoints.loc[knowledgePoints['node']==node, 'points'].iloc[0]\n",
    "        except:\n",
    "            print(node)\n",
    "            display(nodeValues)\n",
    "            display(knowledgePoints)\n",
    "            display(knowledgePoints.loc[knowledgePoints['node']==node, :])\n",
    "            assert False\n",
    "        # skip if node not unlocked\n",
    "        if knowledge == -1:\n",
    "            continue\n",
    "        \n",
    "        breakpoints = np.arange(start=0, stop=knowledge+1, step=5)\n",
    "        for breakpoint in breakpoints:\n",
    "            try:\n",
    "                statValue += nodeValues[node][breakpoint]\n",
    "            except:\n",
    "                display(node)\n",
    "                display(breakpoint)\n",
    "                display(nodeValues)\n",
    "                display(knowledgePoints)\n",
    "                assert False\n",
    "        statValue += nodeValues[node]['scaling']*knowledge\n",
    "        \n",
    "    return statValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7948ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateReagents(reagents: dict, replacementIDs: dict):\n",
    "    return {replacementIDs.get(reagent, reagent):count for reagent,count in reagents.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f4651d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profession:\n",
    "    __all_data = None\n",
    "    __name = None\n",
    "    \n",
    "    def __init__(self, profession):\n",
    "        self.__all_data = list()\n",
    "        self.__name = profession\n",
    "        \n",
    "    def add(self, itemName, itemID, reagents, crafterName, tag, difficulty, multicraft, quantity, skill,\n",
    "            rarity, hasReagentQualities, hasEmbellishmentSlot, hasMissiveSlot, hasSafetyComponent, hasCrestSlot):\n",
    "\n",
    "            self.__all_data.append([self.__name, crafterName, itemID, itemName, None, reagents, tag, rarity, \n",
    "                                    difficulty, skill, quantity, multicraft, hasReagentQualities, \n",
    "                                    hasEmbellishmentSlot, hasMissiveSlot, hasSafetyComponent, hasCrestSlot])\n",
    "            \n",
    "    def get_table(self):\n",
    "        columns = ['profession', 'character', 'itemID', 'item', 'icon', 'reagents', 'tag', 'rarity', \n",
    "                   'difficulty', 'skill1', 'baseQuantity', 'multicraftPercent', 'hasReagentQualities', \n",
    "                   'hasEmbellishmentSlot', 'hasMissiveSlot', 'hasSafetyComponent', 'hasCrestSlot']\n",
    "        dtypes = ['string', 'string', 'int32', 'string', 'string', 'object', 'string', 'string', float, float, \n",
    "                  'string', float, bool, bool, bool, bool, bool, bool]\n",
    "        df = pd.DataFrame(columns=columns, data=self.__all_data)\n",
    "        return df.astype(dict(zip(columns, dtypes)))\n",
    "        \n",
    "    def set_table(self, df):\n",
    "        self.__all_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb8f3d",
   "metadata": {},
   "source": [
    "# Initial DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ede151",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_columns = ['itemID', 'item', 'icon', 'tag', 'rarity']\n",
    "items_dtypes = ['int32', 'string', 'string', 'string', 'string']\n",
    "items = pd.DataFrame(columns=items_columns)\n",
    "\n",
    "professions_columns = ['profession', 'itemID', 'reagents', 'hasReagentQualities', 'hasEmbellishmentSlot',\n",
    "                       'hasMissiveSlot', 'hasSafetyComponent', 'hasCrestSlot']\n",
    "professions_dtypes = ['string', 'int32', dict, bool, bool, bool, bool, bool]\n",
    "professions = pd.DataFrame(columns=professions_columns)\n",
    "\n",
    "crafting_columns = ['itemID', 'difficulty', 'character', 'skill1', 'base_quantity', 'multicraft_percent']\n",
    "crafting_dtypes = ['int32', 'int16', 'string', float, 'string', float]\n",
    "crafting = pd.DataFrame(columns=crafting_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c7f454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseStats = pd.read_csv(DATA_DIR+'base_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52c9ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alchemy = getProfession(DATA_DIR+'alchemy.csv', 'Alchemy')\n",
    "alchemy2 = getProfession(DATA_DIR+'alchemy2.csv', 'Alchemy')\n",
    "blacksmithing = getProfession(DATA_DIR+'blacksmithing.csv', 'Blacksmithing')\n",
    "blacksmithing2 = getProfession(DATA_DIR+'blacksmithing2.csv', 'Blacksmithing')\n",
    "cooking = getProfession(DATA_DIR+'cooking.csv', 'Cooking')\n",
    "enchanting = getProfession(DATA_DIR+'enchanting.csv', 'Enchanting')\n",
    "enchanting2 = getProfession(DATA_DIR+'enchanting2.csv', 'Enchanting')\n",
    "engineering = getProfession(DATA_DIR+'engineering.csv', 'Engineering')\n",
    "inscription = getProfession(DATA_DIR+'inscription.csv', 'Inscription')\n",
    "inscription2 = getProfession(DATA_DIR+'inscription2.csv', 'Inscription')\n",
    "jewelcrafting = getProfession(DATA_DIR+'jewelcrafting.csv', 'Jewelcrafting')\n",
    "jewelcrafting2 = getProfession(DATA_DIR+'jewelcrafting2.csv', 'Jewelcrafting')\n",
    "leatherworking = getProfession(DATA_DIR+'leatherworking.csv', 'Leatherworking')\n",
    "leatherworking2 = getProfession(DATA_DIR+'leatherworking2.csv', 'Leatherworking')\n",
    "tailoring = getProfession(DATA_DIR+'tailoring.csv', 'Tailoring')\n",
    "tailoring2 = getProfession(DATA_DIR+'tailoring2.csv', 'Tailoring')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8050ca",
   "metadata": {},
   "source": [
    "# DataFrame Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6658277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate tables\n",
    "#sort by itemID and skill (descending) so items are paired with higher skill on top\n",
    "#keep the first entry for each itemID (i.e., the highest skill entry)\n",
    "#break same skill tie by sorting by name such that primary crafter is at the top\n",
    "sortCols = ['itemID', 'skill1', 'character']\n",
    "sortVals = [True, False]\n",
    "nameAscending = {'alchemy': False,\n",
    "                 'blacksmithing': False,\n",
    "                 'enchanting': True,\n",
    "                 'inscription': False,\n",
    "                 'jewelcrafting': True,\n",
    "                 'leatherworking': True,\n",
    "                 'tailoring': False}\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "for df1, df2, name in [(alchemy, alchemy2, 'alchemy'), (blacksmithing, blacksmithing2, 'blacksmithing'),\n",
    "                       (enchanting, enchanting2, 'enchanting'), (inscription, inscription2, 'inscription'),\n",
    "                       (jewelcrafting, jewelcrafting2, 'jewelcrafting'), \n",
    "                       (leatherworking, leatherworking2, 'leatherworking'), (tailoring, tailoring2, 'tailoring')]:\n",
    "    df = pd.concat((df1.get_table(), df2.get_table()), ignore_index=True)\n",
    "    df = df.sort_values(by=['itemID', 'skill1', 'character'], ascending=[True, False]+[nameAscending[name]])\n",
    "    df = df.groupby('itemID', as_index=False).head(1)\n",
    "    all_data = pd.concat((all_data, df), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6de4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((all_data, cooking.get_table()), ignore_index=True)\n",
    "all_data = pd.concat((all_data, engineering.get_table()), ignore_index=True)\n",
    "all_data = all_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58408bf4",
   "metadata": {},
   "source": [
    "# Manual Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb22fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixes = {'\"Magically \"\"Infinite\"\" Messenger\"': 'Magically \"Infinite\" Messenger'}\n",
    "all_data['item'] = all_data['item'].apply(lambda x: fixes.get(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1825d1",
   "metadata": {},
   "source": [
    "# Items DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efca3d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 609/609 [00:30<00:00, 20.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#single dataframe of all items, including those listed in reagents\n",
    "columns = ['itemID', 'item', 'icon']\n",
    "items = all_data.loc[:, ['itemID', 'item', 'icon']]\n",
    "items = items.drop_duplicates()\n",
    "        \n",
    "for index, row in tqdm(all_data.iterrows(), total=len(all_data)):\n",
    "    for reagent in row['reagents'].keys():\n",
    "        if reagent not in items.loc[:, 'itemID'].to_numpy():\n",
    "            url = f'https://www.wowhead.com/item={reagent}?xml'\n",
    "            html = requests.get(url).text\n",
    "            soup = BeautifulSoup(html, features='xml')\n",
    "            name = soup.find('name').text\n",
    "            df = pd.DataFrame(columns=columns, data=[[reagent, name, None]])\n",
    "            items = pd.concat((items, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5f122",
   "metadata": {},
   "source": [
    "# Item Icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd122d32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=24)]: Done  13 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=24)]: Done  24 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=24)]: Done  37 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=24)]: Done  50 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=24)]: Done  65 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=24)]: Done  80 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=24)]: Done  97 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=24)]: Done 133 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=24)]: Done 173 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=24)]: Done 194 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=24)]: Done 217 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=24)]: Done 240 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=24)]: Done 265 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=24)]: Done 290 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:   44.1s\n",
      "[Parallel(n_jobs=24)]: Done 344 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=24)]: Done 373 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=24)]: Done 433 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=24)]: Done 464 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=24)]: Done 497 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=24)]: Done 530 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=24)]: Done 565 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=24)]: Done 600 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=24)]: Done 637 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=24)]: Done 704 out of 704 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "method = \"UPDATE\"\n",
    "icon_file = STATIC_DIR+'icons.pkl'\n",
    "\n",
    "if not os.path.isfile(icon_file) or method == \"UPDATE\":\n",
    "    num_cores = joblib.cpu_count()\n",
    "    all_jobs = [joblib.delayed(scrapeIcon)(itemID) for itemID in items['itemID'].values]\n",
    "    results = joblib.Parallel(n_jobs=num_cores, verbose=10)(all_jobs)\n",
    "    icon_links = {int(k):v for d in results for k,v in d.items()}\n",
    "    icons_df = pd.DataFrame()\n",
    "    icons_df['itemID'] = icon_links.keys()\n",
    "    icons_df['link'] = icon_links.values()\n",
    "    icons_df.to_pickle(icon_file)\n",
    "elif os.path.isfile(icon_file) and method == \"LOAD\":\n",
    "    icon_links = pd.read_pickle(icon_file)\n",
    "    icon_links = dict(zip(icon_links['itemID'].values, icon_links['link']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b9ff629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update icons in dataframes\n",
    "all_data['icon'] = all_data['itemID'].map(icon_links)\n",
    "items['icon'] = items['itemID'].map(icon_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38511635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure all items have icons\n",
    "df = all_data.loc[all_data['icon'].isna(), ['itemID', 'icon']]\n",
    "assert(len(df)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d754fd",
   "metadata": {},
   "source": [
    "# Update ItemIDs to be Rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e37ad1ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=24)]: Done  13 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=24)]: Done  24 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=24)]: Done  37 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=24)]: Done  50 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=24)]: Done  65 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=24)]: Done  80 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=24)]: Done  97 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=24)]: Done 133 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=24)]: Done 173 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=24)]: Done 194 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=24)]: Done 217 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=24)]: Done 240 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=24)]: Done 265 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=24)]: Done 290 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=24)]: Done 344 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=24)]: Done 373 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=24)]: Done 433 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=24)]: Done 464 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=24)]: Done 497 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=24)]: Done 530 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=24)]: Done 565 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=24)]: Done 600 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=24)]: Done 637 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=24)]: Done 704 out of 704 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "method = \"UPDATE\"\n",
    "itemIDfile = STATIC_DIR+'itemIDUpdates.pkl'\n",
    "\n",
    "if not os.path.isfile(itemIDfile) or method == 'UPDATE':\n",
    "    old_ids = items['itemID'].astype(int).to_numpy()\n",
    "    all_jobs = [joblib.delayed(check_id)(old_id) for old_id in old_ids]\n",
    "    results = joblib.Parallel(n_jobs=num_cores, verbose=10)(all_jobs)\n",
    "    new_ids = {int(k):int(v) for d in results for k,v in d.items()}\n",
    "    new_ids_df = pd.DataFrame()\n",
    "    new_ids_df['oldID'] = new_ids.keys()\n",
    "    new_ids_df['newID'] = new_ids.values()\n",
    "    new_ids_df.to_pickle(itemIDfile)\n",
    "elif os.path.isfile(itemIDfile) and method == 'LOAD':\n",
    "    new_ids = pd.read_pickle(itemIDfile)\n",
    "    new_ids = dict(zip(new_ids['oldID'].values, new_ids['newID'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c08f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual ID fixes\n",
    "for old_id in new_ids.keys():\n",
    "    if old_id in range(224300, 224324): #gleeful glamours\n",
    "        new_ids[old_id] = old_id+48\n",
    "    elif old_id == 219952: #refulgent crystal\n",
    "        new_ids[old_id] = 219955\n",
    "    elif old_id == 212670: #thunderous hide\n",
    "        new_ids[old_id] = 212673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb625974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure all items with a rank 3 are listed at rank 3\n",
    "assert -1 not in new_ids.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dc747a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update itemIDs in both dataframes\n",
    "all_data['itemID'] = all_data['itemID'].map(new_ids)\n",
    "items['itemID'] = items['itemID'].map(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4f82131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update all item ids that are not at rank 3 with the found rank 3 ids\n",
    "all_data['reagents'] = all_data['reagents'].apply(updateReagents, args=(new_ids,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055ed7b",
   "metadata": {},
   "source": [
    "# Add Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a060e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all mats rank 2\n",
    "all_data['skill2'] = all_data['skill1']+all_data['difficulty']*0.2\n",
    "\n",
    "#all mats rank 3\n",
    "all_data['skill3'] = all_data['skill1']+all_data['difficulty']*0.4\n",
    "\n",
    "extraDiff = {'safetyComponent':10,\n",
    "             'missive':5,\n",
    "             'embellishment':5,\n",
    "             'weatheredCrest':100,\n",
    "             'runedCrest':10,\n",
    "             'gildedCrest':20,\n",
    "             'combatant':0,\n",
    "             'aspirant':50,\n",
    "             'gladiator':150}\n",
    "\n",
    "#safetycomponent+embellishment not currently possible\n",
    "all_data['difficulty_safetycomponent'] = all_data['difficulty'] + extraDiff['safetyComponent']\n",
    "all_data['difficulty_missive'] = all_data['difficulty'] + extraDiff['missive']\n",
    "all_data['difficulty_embellishment'] = all_data['difficulty'] + extraDiff['embellishment']\n",
    "all_data['difficulty_safetycomponent_missive'] = all_data['difficulty']\n",
    "all_data['difficulty_missive_embellishment'] = all_data['difficulty'] + extraDiff['missive'] + extraDiff['embellishment']\n",
    "all_data['difficulty_weathered'] = all_data['difficulty'] + extraDiff['weatheredCrest']\n",
    "all_data['difficulty_weathered_safetycomponent'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['safetyComponent']\n",
    "all_data['difficulty_weathered_missive'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['missive']\n",
    "all_data['difficulty_weathered_embellishment'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['embellishment']\n",
    "all_data['difficulty_weathered_safetycomponent_missive'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['safetyComponent'] + extraDiff['missive']\n",
    "all_data['difficulty_weathered_missive_embellishment'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['missive'] + extraDiff['embellishment']\n",
    "all_data['difficulty_runed'] = all_data['difficulty'] + extraDiff['runedCrest']\n",
    "all_data['difficulty_runed_safetycomponent'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['safetyComponent']\n",
    "all_data['difficulty_runed_missive'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['missive']\n",
    "all_data['difficulty_runed_embellishment'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['embellishment']\n",
    "all_data['difficulty_runed_safetycomponent_missive'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['safetyComponent'] + extraDiff['missive']\n",
    "all_data['difficulty_runed_missive_embellishment'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['missive'] + extraDiff['embellishment']\n",
    "all_data['difficulty_gilded'] = all_data['difficulty'] + extraDiff['gildedCrest']\n",
    "all_data['difficulty_gilded_safetycomponent'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['safetyComponent']\n",
    "all_data['difficulty_gilded_missive'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['missive']\n",
    "all_data['difficulty_gilded_embellishment'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['embellishment']\n",
    "all_data['difficulty_gilded_safetycomponent_missive'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['safetyComponent'] + extraDiff['missive']\n",
    "all_data['difficulty_gilded_missive_embellishment'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['missive'] + extraDiff['embellishment']\n",
    "all_data['difficulty_combatant'] = all_data['difficulty']+extraDiff['combatant']\n",
    "all_data['difficulty_combatant_missive'] = all_data['difficulty']+extraDiff['combatant']+extraDiff['missive']\n",
    "all_data['difficulty_combatant_embellishment'] = all_data['difficulty']+extraDiff['combatant']+extraDiff['embellishment']\n",
    "all_data['difficulty_combatant_missive_embellishment'] = all_data['difficulty']+extraDiff['combatant']+extraDiff['missive']+extraDiff['embellishment']\n",
    "all_data['difficulty_aspirant'] = all_data['difficulty']+extraDiff['aspirant']\n",
    "all_data['difficulty_aspirant_missive'] = all_data['difficulty']+extraDiff['aspirant']+extraDiff['missive']\n",
    "all_data['difficulty_aspirant_embellishment'] = all_data['difficulty']+extraDiff['aspirant']+extraDiff['embellishment']\n",
    "all_data['difficulty_aspirant_missive_embellishment'] = all_data['difficulty']+extraDiff['aspirant']+extraDiff['missive']+extraDiff['embellishment']\n",
    "all_data['difficulty_gladiator'] = all_data['difficulty']+extraDiff['gladiator']\n",
    "all_data['difficulty_gladiator_missive'] = all_data['difficulty']+extraDiff['gladiator']+extraDiff['missive']\n",
    "all_data['difficulty_gladiator_embellishment'] = all_data['difficulty']+extraDiff['gladiator']+extraDiff['embellishment']\n",
    "all_data['difficulty_gladiator_missive_embellishment'] = all_data['difficulty']+extraDiff['gladiator']+extraDiff['missive']+extraDiff['embellishment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c70485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = ['', '_safetycomponent', '_missive', '_embellishment', '_safetycomponent_missive', \n",
    "             '_missive_embellishment', '_weathered', '_weathered_safetycomponent', \n",
    "             '_weathered_safetycomponent_missive', '_weathered_missive', '_weathered_embellishment',\n",
    "             '_weathered_missive_embellishment', '_runed', '_runed_safetycomponent', '_runed_safetycomponent_missive', '_runed_missive',\n",
    "             '_runed_embellishment', '_runed_missive_embellishment', '_gilded', '_gilded_safetycomponent', \n",
    "             '_gilded_missive', '_gilded_safetycomponent_missive', '_gilded_embellishment', \n",
    "             '_gilded_missive_embellishment', '_combatant', '_combatant_missive', '_combatant_embellishment', \n",
    "             '_combatant_missive_embellishment', '_aspirant', '_aspirant_missive', '_aspirant_embellishment', \n",
    "             '_aspirant_missive_embellishment', '_gladiator', '_gladiator_missive', '_gladiator_embellishment', \n",
    "             '_gladiator_missive_embellishment']\n",
    "    \n",
    "for modifier in modifiers:\n",
    "    all_data['rank1mats_outcome'+modifier] = all_data.apply(lambda row: outcomeQuality(row['skill1'], \n",
    "                                                                                       row['difficulty'+modifier], \n",
    "                                                                                       row['tag']), axis=1)\n",
    "    all_data['rank2mats_outcome'+modifier] = all_data.apply(lambda row: outcomeQuality(row['skill2'], \n",
    "                                                                                       row['difficulty'+modifier], \n",
    "                                                                                       row['tag']), axis=1)\n",
    "    all_data['rank3mats_outcome'+modifier] = all_data.apply(lambda row: outcomeQuality(row['skill3'], \n",
    "                                                                                       row['difficulty'+modifier], \n",
    "                                                                                       row['tag']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82873fcd",
   "metadata": {},
   "source": [
    "# Proper Case tag field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83d02ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['tag'] = all_data['tag'].apply(lambda x: x.title() if x != \"gear (pvp)\" else \"Gear (PvP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca45f9",
   "metadata": {},
   "source": [
    "# Remove pd.NA and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b81e6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "all_data['character'] = all_data['character'].replace({pd.NA:None, 'None':None})\n",
    "all_data = all_data.sort_values(by=['profession', 'item'], ascending=[True, True])\n",
    "\n",
    "assert(len(all_data['character'].unique()==8) or len(all_data['character'].unique()==9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fd3c5",
   "metadata": {},
   "source": [
    "# File Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0b8a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.to_pickle(STATIC_DIR+'items_TWW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5af7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_pickle(STATIC_DIR+'data_TWW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e15b3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_pickle(STATIC_DIR+'items_TWW.pkl')\n",
    "all_data = pd.read_pickle(STATIC_DIR+'data_TWW.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc35cf",
   "metadata": {},
   "source": [
    "# Issue Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "113ec4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profession</th>\n",
       "      <th>character</th>\n",
       "      <th>itemID</th>\n",
       "      <th>item</th>\n",
       "      <th>icon</th>\n",
       "      <th>reagents</th>\n",
       "      <th>tag</th>\n",
       "      <th>rarity</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>skill1</th>\n",
       "      <th>...</th>\n",
       "      <th>rank3mats_outcome_gladiator</th>\n",
       "      <th>rank1mats_outcome_gladiator_missive</th>\n",
       "      <th>rank2mats_outcome_gladiator_missive</th>\n",
       "      <th>rank3mats_outcome_gladiator_missive</th>\n",
       "      <th>rank1mats_outcome_gladiator_embellishment</th>\n",
       "      <th>rank2mats_outcome_gladiator_embellishment</th>\n",
       "      <th>rank3mats_outcome_gladiator_embellishment</th>\n",
       "      <th>rank1mats_outcome_gladiator_missive_embellishment</th>\n",
       "      <th>rank2mats_outcome_gladiator_missive_embellishment</th>\n",
       "      <th>rank3mats_outcome_gladiator_missive_embellishment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Alchemy</td>\n",
       "      <td>None</td>\n",
       "      <td>212514</td>\n",
       "      <td>Gleaming Glory</td>\n",
       "      <td>https://wow.zamimg.com/images/wow/icons/large/...</td>\n",
       "      <td>{211805: 80}</td>\n",
       "      <td>Crafting Reagent</td>\n",
       "      <td>epic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   profession character  itemID            item  \\\n",
       "28    Alchemy      None  212514  Gleaming Glory   \n",
       "\n",
       "                                                 icon      reagents  \\\n",
       "28  https://wow.zamimg.com/images/wow/icons/large/...  {211805: 80}   \n",
       "\n",
       "                 tag rarity  difficulty  skill1  ...  \\\n",
       "28  Crafting Reagent   epic         NaN     NaN  ...   \n",
       "\n",
       "   rank3mats_outcome_gladiator  rank1mats_outcome_gladiator_missive  \\\n",
       "28                           0                                    0   \n",
       "\n",
       "    rank2mats_outcome_gladiator_missive  rank3mats_outcome_gladiator_missive  \\\n",
       "28                                    0                                    0   \n",
       "\n",
       "    rank1mats_outcome_gladiator_embellishment  \\\n",
       "28                                          0   \n",
       "\n",
       "    rank2mats_outcome_gladiator_embellishment  \\\n",
       "28                                          0   \n",
       "\n",
       "    rank3mats_outcome_gladiator_embellishment  \\\n",
       "28                                          0   \n",
       "\n",
       "    rank1mats_outcome_gladiator_missive_embellishment  \\\n",
       "28                                                  0   \n",
       "\n",
       "    rank2mats_outcome_gladiator_missive_embellishment  \\\n",
       "28                                                  0   \n",
       "\n",
       "    rank3mats_outcome_gladiator_missive_embellishment  \n",
       "28                                                  0  \n",
       "\n",
       "[1 rows x 162 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data['item']=='Gleaming Glory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de2476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
