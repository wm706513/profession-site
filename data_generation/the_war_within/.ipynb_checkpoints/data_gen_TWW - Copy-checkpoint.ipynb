{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "218072f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import re\n",
    "import joblib\n",
    "import string\n",
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57400fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "lastTime = startTime\n",
    "times = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0fed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd492d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "STATIC_DIR = '../../static/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9d1ed",
   "metadata": {},
   "source": [
    "# Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f4651d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profession:\n",
    "    __all_data = None\n",
    "    __name = None\n",
    "    \n",
    "    def __init__(self, profession):\n",
    "        self.__all_data = list()\n",
    "        self.__name = profession\n",
    "        \n",
    "    def add(self, itemID, itemName, reagents, crafterName, tag, difficulty, multicraft, quantity, skill,\n",
    "            rarity, hasReagentQualities, hasEmbellishmentSlot, hasMissiveSlot, hasSafetyComponent, hasCrestSlot):\n",
    "\n",
    "            self.__all_data.append([self.__name, crafterName, itemID, itemName, None, reagents, tag, rarity, \n",
    "                                    difficulty, skill, quantity, multicraft, hasReagentQualities, \n",
    "                                    hasEmbellishmentSlot, hasMissiveSlot, hasSafetyComponent, hasCrestSlot])\n",
    "            \n",
    "    def get_table(self):\n",
    "        columns = ['profession', 'character', 'itemID', 'item', 'icon', 'reagents', 'tag', 'rarity', \n",
    "                   'difficulty', 'skill1', 'baseQuantity', 'multicraftPercent', 'hasReagentQualities', \n",
    "                   'hasEmbellishmentSlot', 'hasMissiveSlot', 'hasSafetyComponent', 'hasCrestSlot']\n",
    "        dtypes = ['string', 'string', 'int32', 'string', 'string', 'object', 'string', 'string', float, float, \n",
    "                  'string', float, bool, bool, bool, bool, bool, bool]\n",
    "        df = pd.DataFrame(columns=columns, data=self.__all_data)\n",
    "        return df.astype(dict(zip(columns, dtypes)))\n",
    "        return df\n",
    "        \n",
    "    def set_table(self, df):\n",
    "        self.__all_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e8905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReagents(professionName, itemID, itemName):\n",
    "    with open(DATA_DIR+professionName.lower()+'_recipes.json') as file:\n",
    "        recipes = json.load(file)\n",
    "        \n",
    "    for recipe in recipes:\n",
    "        if recipe.get('itemID')==str(itemID) and recipe.get('itemName')==itemName:\n",
    "            return recipe.get('reagents')\n",
    "    else:\n",
    "        raise KeyError(f'Item ID \"{itemID}\" with item name \"{itemName}\" not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40c0a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(professionName, characterName, itemID, itemName, \n",
    "             stats=['skill', 'multicraft', 'resourcefulness', 'ingenuity']):\n",
    "    assert type(stats)==list, 'stats must be a list of strings'\n",
    "    for stat in stats:\n",
    "        assert stat.lower() in ['skill', 'multicraft', 'resourcefulness', 'ingenuity'], f'{stat} is not valid'\n",
    "    stats = [stat.lower() for stat in stats]\n",
    "    \n",
    "    #character profession knowledge points\n",
    "    knowledge = pd.read_csv(DATA_DIR+professionName+'_knowledge.csv')\n",
    "    assert characterName in knowledge.columns, f'{characterName} does not know {professionName} [Err:knowledge]'\n",
    "    knowledge = knowledge.loc[:, ['node', characterName]]\n",
    "    \n",
    "    #skill, resourcefulness, ingenuity, and multicraft stats from each node\n",
    "    with open(DATA_DIR+professionName+'_nodes.json') as file:\n",
    "        nodes = json.load(file)   \n",
    "        \n",
    "    #which nodes affect which recipes\n",
    "    with open(DATA_DIR+professionName+'_specializations.json') as file:\n",
    "        specializations = json.load(file)\n",
    "        for spec in specializations:\n",
    "            if spec.get('itemID')==str(itemID) and spec.get('itemName')==itemName:\n",
    "                specializations = spec.get('nodes')\n",
    "                break\n",
    "        else:\n",
    "            raise KeyError(f'Item ID \"{itemID}\" with item name \"{itemName}\" not found')\n",
    "        \n",
    "    stats = dict(zip(stats, np.zeros(len(stats))))\n",
    "    for stat in stats.keys():\n",
    "        statValues = nodes.get(stat)\n",
    "        for spec in specializations:\n",
    "            try:\n",
    "                knowledgePoints = int(knowledge.loc[knowledge['node']==spec, characterName])\n",
    "            except:\n",
    "                display(knowledge)\n",
    "                display(spec)\n",
    "                display(characterName)\n",
    "                display(knowledge.loc[knowledge['node']==spec, characterName])\n",
    "                \n",
    "            #node not unlocked yet, so don't count it\n",
    "            if knowledgePoints == -1:\n",
    "                continue\n",
    "                \n",
    "            #apply stat gained per point in spec node\n",
    "            stats[stat] += int(statValues.get(spec).get('scaling'))*knowledgePoints\n",
    "            \n",
    "            #apply stat gained from achieved breakpoints in spec node\n",
    "            for breakpoint in np.arange(start=0, stop=knowledgePoints+1, step=5):\n",
    "                stats[stat] += int(statValues.get(spec).get(str(breakpoint)))\n",
    "        \n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9c1243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProfession(professionName, characterName):\n",
    "    professionName = professionName.lower()\n",
    "    \n",
    "    validProfessions = ['alchemy', 'blacksmithing', 'cooking', 'enchanting', 'engineering', 'inscription', \n",
    "                        'jewelcrafting', 'leatherworking', 'tailoring']\n",
    "    assert professionName.lower() in validProfessions, f'{professionName} is not a valid profession'\n",
    "    \n",
    "    #base values from profession level and equipment\n",
    "    baseValues = pd.read_csv(DATA_DIR+'base_stats.csv')\n",
    "    baseValues = baseValues.loc[(baseValues['profession']==professionName)&(baseValues['character']==characterName),\n",
    "                                baseValues.columns]\n",
    "    assert len(baseValues)==1, 'Issue with base values table'\n",
    "    baseValues = baseValues.to_dict(orient='records')[0]\n",
    "    \n",
    "    #attributes for each recipe (tag, difficulty, base stats, rarity, embellishments, etc)\n",
    "    items = pd.read_csv(DATA_DIR+professionName+'_items.csv')\n",
    "    \n",
    "    #which recipes each character knows\n",
    "    learned = pd.read_csv(DATA_DIR+professionName+'_learned.csv')\n",
    "    assert characterName in learned.columns, f'{characterName} does not know {professionName} [Err:learned]'\n",
    "    learned = learned.loc[:, ['itemID', 'itemName', characterName]]\n",
    "    \n",
    "    profession = Profession(professionName)\n",
    "    \n",
    "    #set crafter to None if not learned by character, otherwise set to character name\n",
    "    table = pd.merge(left=items, right=learned, on=['itemID', 'itemName'], how='outer', suffixes=[None, None])\n",
    "    table['crafter'] = None\n",
    "    try:\n",
    "        table.loc[table[characterName], 'crafter'] = characterName\n",
    "    except:\n",
    "        display(characterName)\n",
    "        display(table)\n",
    "        \n",
    "    for index, row in table.iterrows():   \n",
    "        itemID = row['itemID']\n",
    "        itemName = row['itemName']\n",
    "        \n",
    "        #adjust values to allow for np.nan since you can't do float('np.nan')\n",
    "        try:\n",
    "            skill = float(row['skill'])\n",
    "        except:\n",
    "            skill = np.nan\n",
    "        \n",
    "        try:\n",
    "            multicraft = float(row['multicraft'])\n",
    "        except:\n",
    "            multicraft = np.nan\n",
    "            \n",
    "        try:\n",
    "            difficulty = float(row['difficulty'])\n",
    "        except:\n",
    "            difficulty = np.nan\n",
    "            \n",
    "        skill += (baseValues.get('level') + baseValues.get('skill'))\n",
    "        multicraft += baseValues.get('multicraft')\n",
    "        multicraft = np.round(multicraft/33*100, 1) #convert to a percent stat rather than stat value\n",
    "        \n",
    "        if professionName != 'cooking':\n",
    "            stats = getStats(professionName, characterName, itemID, itemName)\n",
    "        else:\n",
    "            stats = dict(zip(['skill', 'multicraft', 'resourcefulness', 'ingenuity'], [0,0,0,0]))\n",
    "            \n",
    "        profession.add(itemID = itemID,\n",
    "                       itemName = itemName,\n",
    "                       reagents = getReagents(professionName, itemID, itemName),\n",
    "                       crafterName = characterName,\n",
    "                       tag = row['tag'],\n",
    "                       difficulty = difficulty,\n",
    "                       multicraft = multicraft + stats['multicraft'],\n",
    "                       quantity = row['quantity'],\n",
    "                       skill = skill + stats['skill'],\n",
    "                       rarity = row['rarity'],\n",
    "                       hasReagentQualities = row['hasReagentQualities'],\n",
    "                       hasEmbellishmentSlot = row['hasEmbellishmentSlot'],\n",
    "                       hasMissiveSlot = row['hasMissiveSlot'],\n",
    "                       hasSafetyComponent = row['hasSafetyComponent'],\n",
    "                       hasCrestSlot = row['hasCrestSlot']\n",
    "                      )\n",
    "        \n",
    "    return profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a667c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeIcon(itemID):\n",
    "    url = f'https://www.wowhead.com/item={itemID}'\n",
    "    soup = BeautifulSoup(requests.get(url).text) \n",
    "    \n",
    "    #string1 finds strings preceded by:   \"{itemID}:{\" \n",
    "    #and are also followed by:    ,\"screenshot\"\n",
    "    #the strings cannot include the symbol:   }\n",
    "    string1 = re.search(r'(?<=\"'+f'{itemID}'+r'\":{)[^}]+(?=,\"screenshot\")', str(soup)).group()\n",
    "    \n",
    "    #string2 searches string1 for strings preceded by:      \"icon\":\"\n",
    "    #and are also followed by:      \")\n",
    "    #that only contain a-z, A-Z, 0-9, _, and -\n",
    "    string2 = re.search(r'(?<=\"icon\":\")[\\w-]+(?=\")', string1).group()\n",
    "    site = 'https://wow.zamimg.com/images/wow/icons/large/'+string2+'.jpg'\n",
    "    \n",
    "    status_code = requests.get(site).status_code\n",
    "    \n",
    "    if status_code==200:\n",
    "        return {itemID: site}\n",
    "    else:\n",
    "        return {itemID: None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "420c9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_id(old_id):\n",
    "    url = f'https://www.wowhead.com/item={old_id}?xml'\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, features='xml')\n",
    "    name = soup.find('name').text\n",
    "    text = soup.find('htmlTooltip').text\n",
    "    \n",
    "    #check for quality tier information\n",
    "    if text.find('quality-tier1') >= 0:\n",
    "        new_id = old_id+2\n",
    "        new_id_lower = old_id-2\n",
    "    elif text.find('quality-tier2') >= 0:\n",
    "        new_id = old_id+1\n",
    "        new_id_lower = old_id-1\n",
    "    else: #either its tier3 or it doesn't have tiers, in which use the old_id\n",
    "        return {old_id: old_id}\n",
    "    \n",
    "    \n",
    "    #wasn't a tier 3 item, so check the calculated id for if the name matches and is tier 3\n",
    "    #return the new id if it is the same name and tier 3, else return -1 for manual checking\n",
    "    try:\n",
    "        url = f'https://www.wowhead.com/item={new_id}?xml'\n",
    "        html = requests.get(url).text\n",
    "        soup = BeautifulSoup(html, features='xml')\n",
    "        if soup.find('name').text == name and soup.find('htmlTooltip').text.find('quality-tier3') >= 0:\n",
    "            return {old_id: new_id}\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        url = f'https://www.wowhead.com/item={new_id_lower}?xml'\n",
    "        html = requests.get(url).text\n",
    "        soup = BeautifulSoup(html, features='xml')\n",
    "        if soup.find('name').text == name and soup.find('htmlTooltip').text.find('quality-tier3') >= 0:\n",
    "            return {old_id: new_id_lower}\n",
    "    except:\n",
    "        return {old_id: -1}\n",
    "        \n",
    "    return {old_id: -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4ec477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcomeQuality(skill, difficulty, tag):\n",
    "    if tag.lower()[:4]=='gear':\n",
    "        arr = np.array([1, 0.2*difficulty, 0.5*difficulty, 0.8*difficulty, difficulty])\n",
    "    else:\n",
    "        arr = np.array([1, 0.5*difficulty, difficulty])\n",
    "        \n",
    "    return (skill >= arr).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7948ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateReagents(reagents: dict, replacementIDs: dict):\n",
    "    return {replacementIDs.get(reagent, reagent):count for reagent,count in reagents.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfe5bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['functions'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb8f3d",
   "metadata": {},
   "source": [
    "# Initial DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5ede151",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_columns = ['itemID', 'item', 'icon', 'tag', 'rarity']\n",
    "items_dtypes = ['int32', 'string', 'string', 'string', 'string']\n",
    "items = pd.DataFrame(columns=items_columns)\n",
    "\n",
    "professions_columns = ['profession', 'itemID', 'reagents', 'hasReagentQualities', 'hasEmbellishmentSlot',\n",
    "                       'hasMissiveSlot', 'hasSafetyComponent', 'hasCrestSlot']\n",
    "professions_dtypes = ['string', 'int32', dict, bool, bool, bool, bool, bool]\n",
    "professions = pd.DataFrame(columns=professions_columns)\n",
    "\n",
    "crafting_columns = ['itemID', 'difficulty', 'character', 'skill1', 'base_quantity', 'multicraft_percent']\n",
    "crafting_dtypes = ['int32', 'int16', 'string', float, 'string', float]\n",
    "crafting = pd.DataFrame(columns=crafting_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52c9ec0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alchemy = getProfession('Alchemy', 'Trillithia')\n",
    "alchemy2 = getProfession('Alchemy', 'Sillik')\n",
    "blacksmithing = getProfession('Blacksmithing', 'Zarastannil')\n",
    "blacksmithing2 = getProfession('Blacksmithing', 'Nystelil')\n",
    "cooking = getProfession('Cooking', 'Trillithia')\n",
    "enchanting = getProfession('Enchanting', 'Linidel')\n",
    "enchanting2 = getProfession('Enchanting', 'Mellasona')\n",
    "engineering = getProfession('Engineering', 'Trillithia')\n",
    "inscription = getProfession('Inscription', 'Mellasona')\n",
    "inscription2 = getProfession('Inscription', 'Lindinil')\n",
    "jewelcrafting = getProfession('Jewelcrafting', 'Nystelil')\n",
    "jewelcrafting2 = getProfession('Jewelcrafting', 'Zarastannil')\n",
    "leatherworking = getProfession('Leatherworking', 'Braevele')\n",
    "leatherworking2 = getProfession('Leatherworking', 'Lindinil')\n",
    "tailoring = getProfession('Tailoring', 'Linidel')\n",
    "tailoring2 = getProfession('Tailoring', 'Braevele')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8050ca",
   "metadata": {},
   "source": [
    "# DataFrame Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6658277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate tables\n",
    "#sort by itemID and skill (descending) so items are paired with higher skill on top\n",
    "#keep the first entry for each itemID (i.e., the highest skill entry)\n",
    "#break same skill tie by sorting by name such that primary crafter is at the top\n",
    "sortCols = ['itemID', 'skill1', 'character']\n",
    "sortVals = [True, False]\n",
    "nameAscending = {'alchemy': False,\n",
    "                 'blacksmithing': False,\n",
    "                 'enchanting': True,\n",
    "                 'inscription': False,\n",
    "                 'jewelcrafting': True,\n",
    "                 'leatherworking': True,\n",
    "                 'tailoring': False}\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "for df1, df2, name in [(alchemy, alchemy2, 'alchemy'), (blacksmithing, blacksmithing2, 'blacksmithing'),\n",
    "                       (enchanting, enchanting2, 'enchanting'), (inscription, inscription2, 'inscription'),\n",
    "                       (jewelcrafting, jewelcrafting2, 'jewelcrafting'), \n",
    "                       (leatherworking, leatherworking2, 'leatherworking'), (tailoring, tailoring2, 'tailoring')]:\n",
    "    table1 = df1.get_table()\n",
    "    table2 = df2.get_table()\n",
    "    \n",
    "    #recipes known by at least one\n",
    "    known = pd.concat((table1[table1['character']!='None'], table2[table2['character']!='None']), ignore_index=True)\n",
    "    \n",
    "    #recipes not known by both\n",
    "    unknown = pd.concat((table1[table1['character']=='None'], table2[table2['character']=='None']), ignore_index=True)\n",
    "    \n",
    "    #only recipes with known crafters are included, so sort by highest skill, then chosen character order\n",
    "    #and only take the first (i.e. the character we want to be displayed)\n",
    "    known = known.sort_values(by=['itemID', 'skill1', 'character'], ascending=[True, False]+[nameAscending[name]])\n",
    "    known = known.groupby('itemID', as_index=False).first()\n",
    "    \n",
    "    #all recipes have crafter as None, so take only the recipe with highest skill if there are duplicates\n",
    "    unknown = unknown.sort_values(by=['itemID', 'skill1'], ascending=[True, False])\n",
    "    unknown = unknown.groupby('itemID', as_index=False).first()\n",
    "    \n",
    "    #*should* (I think) keep known recipes then unknown recipes in that order. So grouping by itemID should put\n",
    "    #known ones before unknown and hence only take the prechosen known recipe, unless it was known by no character\n",
    "    #in which it will only appear once anyway with character=='None', which .first() will collect\n",
    "    df = pd.concat((known, unknown), ignore_index=True)    \n",
    "    \n",
    "    df = df.groupby('itemID', as_index=False).first()\n",
    "    all_data = pd.concat((all_data, df), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((all_data, cooking.get_table()), ignore_index=True)\n",
    "all_data = pd.concat((all_data, engineering.get_table()), ignore_index=True)\n",
    "all_data = all_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58408bf4",
   "metadata": {},
   "source": [
    "# Manual Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb22fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixes = {'\"Magically \"\"Infinite\"\" Messenger\"': 'Magically \"Infinite\" Messenger'}\n",
    "all_data['item'] = all_data['item'].apply(lambda x: fixes.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac70d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['base frames'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1825d1",
   "metadata": {},
   "source": [
    "# Items DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single dataframe of all items, including those listed in reagents\n",
    "columns = ['itemID', 'item', 'icon']\n",
    "items = all_data.loc[:, ['itemID', 'item', 'icon']]\n",
    "items = items.drop_duplicates()\n",
    "        \n",
    "for index, row in tqdm(all_data.iterrows(), total=len(all_data)):\n",
    "    for reagent in row['reagents'].keys():\n",
    "        if reagent not in items.loc[:, 'itemID'].to_numpy():\n",
    "            url = f'https://www.wowhead.com/item={reagent}?xml'\n",
    "            html = requests.get(url).text\n",
    "            soup = BeautifulSoup(html, features='xml')\n",
    "            name = soup.find('name').text\n",
    "            df = pd.DataFrame(columns=columns, data=[[reagent, name, None]])\n",
    "            items = pd.concat((items, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e388a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['items lookup'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5f122",
   "metadata": {},
   "source": [
    "# Item Icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd122d32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method = \"LOAD\"\n",
    "icon_file = STATIC_DIR+'icons.pkl'\n",
    "\n",
    "if not os.path.isfile(icon_file) or method == \"UPDATE\":\n",
    "    num_cores = joblib.cpu_count()\n",
    "    all_jobs = [joblib.delayed(scrapeIcon)(itemID) for itemID in items['itemID'].values]\n",
    "    results = joblib.Parallel(n_jobs=num_cores, verbose=10)(all_jobs)\n",
    "    icon_links = {int(k):v for d in results for k,v in d.items()}\n",
    "    icons_df = pd.DataFrame()\n",
    "    icons_df['itemID'] = icon_links.keys()\n",
    "    icons_df['link'] = icon_links.values()\n",
    "    icons_df.to_pickle(icon_file)\n",
    "elif os.path.isfile(icon_file) and method == \"LOAD\":\n",
    "    icon_links = pd.read_pickle(icon_file)\n",
    "    icon_links = dict(zip(icon_links['itemID'].values, icon_links['link']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ff629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update icons in dataframes\n",
    "all_data['icon'] = all_data['itemID'].map(icon_links)\n",
    "items['icon'] = items['itemID'].map(icon_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38511635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure all items have icons\n",
    "df = all_data.loc[all_data['icon'].isna(), ['itemID', 'icon']]\n",
    "assert(len(df)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f0c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['icons'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d754fd",
   "metadata": {},
   "source": [
    "# Update ItemIDs to be Rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ad1ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method = \"LOAD\"\n",
    "itemIDfile = STATIC_DIR+'itemIDUpdates.pkl'\n",
    "\n",
    "if not os.path.isfile(itemIDfile) or method == 'UPDATE':\n",
    "    old_ids = items['itemID'].astype(int).to_numpy()\n",
    "    all_jobs = [joblib.delayed(check_id)(old_id) for old_id in old_ids]\n",
    "    results = joblib.Parallel(n_jobs=num_cores, verbose=10)(all_jobs)\n",
    "    new_ids = {int(k):int(v) for d in results for k,v in d.items()}\n",
    "    new_ids_df = pd.DataFrame()\n",
    "    new_ids_df['oldID'] = new_ids.keys()\n",
    "    new_ids_df['newID'] = new_ids.values()\n",
    "    new_ids_df.to_pickle(itemIDfile)\n",
    "elif os.path.isfile(itemIDfile) and method == 'LOAD':\n",
    "    new_ids = pd.read_pickle(itemIDfile)\n",
    "    new_ids = dict(zip(new_ids['oldID'].values, new_ids['newID'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual ID fixes\n",
    "for old_id in new_ids.keys():\n",
    "    if old_id in range(224300, 224324): #gleeful glamours\n",
    "        new_ids[old_id] = old_id+48\n",
    "    elif old_id == 219952: #refulgent crystal\n",
    "        new_ids[old_id] = 219955\n",
    "    elif old_id == 212670: #thunderous hide\n",
    "        new_ids[old_id] = 212673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb625974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure all items with a rank 3 are listed at rank 3\n",
    "assert -1 not in new_ids.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc747a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update itemIDs in both dataframes\n",
    "all_data['itemID'] = all_data['itemID'].map(new_ids)\n",
    "items['itemID'] = items['itemID'].map(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f82131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update all item ids that are not at rank 3 with the found rank 3 ids\n",
    "all_data['reagents'] = all_data['reagents'].apply(updateReagents, args=(new_ids,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5281366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['item qualities'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055ed7b",
   "metadata": {},
   "source": [
    "# Add Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all mats rank 2\n",
    "all_data['skill2'] = all_data['skill1']+all_data['difficulty']*0.2\n",
    "\n",
    "#all mats rank 3\n",
    "all_data['skill3'] = all_data['skill1']+all_data['difficulty']*0.4\n",
    "\n",
    "extraDiff = {'safetyComponent':10,\n",
    "             'missive':5,\n",
    "             'embellishment':5,\n",
    "             'weatheredCrest':100,\n",
    "             'runedCrest':10,\n",
    "             'gildedCrest':20,\n",
    "             'combatant':0,\n",
    "             'aspirant':50,\n",
    "             'gladiator':150}\n",
    "\n",
    "#safetycomponent+embellishment not currently possible\n",
    "all_data['difficulty_safetycomponent'] = all_data['difficulty'] + extraDiff['safetyComponent']\n",
    "all_data['difficulty_missive'] = all_data['difficulty'] + extraDiff['missive']\n",
    "all_data['difficulty_embellishment'] = all_data['difficulty'] + extraDiff['embellishment']\n",
    "all_data['difficulty_safetycomponent_missive'] = all_data['difficulty']\n",
    "all_data['difficulty_missive_embellishment'] = all_data['difficulty'] + extraDiff['missive'] + extraDiff['embellishment']\n",
    "all_data['difficulty_weathered'] = all_data['difficulty'] + extraDiff['weatheredCrest']\n",
    "all_data['difficulty_weathered_safetycomponent'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['safetyComponent']\n",
    "all_data['difficulty_weathered_missive'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['missive']\n",
    "all_data['difficulty_weathered_embellishment'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['embellishment']\n",
    "all_data['difficulty_weathered_safetycomponent_missive'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['safetyComponent'] + extraDiff['missive']\n",
    "all_data['difficulty_weathered_missive_embellishment'] = all_data['difficulty'] + extraDiff['weatheredCrest'] + extraDiff['missive'] + extraDiff['embellishment']\n",
    "all_data['difficulty_runed'] = all_data['difficulty'] + extraDiff['runedCrest']\n",
    "all_data['difficulty_runed_safetycomponent'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['safetyComponent']\n",
    "all_data['difficulty_runed_missive'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['missive']\n",
    "all_data['difficulty_runed_embellishment'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['embellishment']\n",
    "all_data['difficulty_runed_safetycomponent_missive'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['safetyComponent'] + extraDiff['missive']\n",
    "all_data['difficulty_runed_missive_embellishment'] = all_data['difficulty'] + extraDiff['runedCrest'] + extraDiff['missive'] + extraDiff['embellishment']\n",
    "all_data['difficulty_gilded'] = all_data['difficulty'] + extraDiff['gildedCrest']\n",
    "all_data['difficulty_gilded_safetycomponent'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['safetyComponent']\n",
    "all_data['difficulty_gilded_missive'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['missive']\n",
    "all_data['difficulty_gilded_embellishment'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['embellishment']\n",
    "all_data['difficulty_gilded_safetycomponent_missive'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['safetyComponent'] + extraDiff['missive']\n",
    "all_data['difficulty_gilded_missive_embellishment'] = all_data['difficulty'] + extraDiff['gildedCrest'] + extraDiff['missive'] + extraDiff['embellishment']\n",
    "all_data['difficulty_combatant'] = all_data['difficulty']+extraDiff['combatant']\n",
    "all_data['difficulty_combatant_missive'] = all_data['difficulty']+extraDiff['combatant']+extraDiff['missive']\n",
    "all_data['difficulty_combatant_embellishment'] = all_data['difficulty']+extraDiff['combatant']+extraDiff['embellishment']\n",
    "all_data['difficulty_combatant_missive_embellishment'] = all_data['difficulty']+extraDiff['combatant']+extraDiff['missive']+extraDiff['embellishment']\n",
    "all_data['difficulty_aspirant'] = all_data['difficulty']+extraDiff['aspirant']\n",
    "all_data['difficulty_aspirant_missive'] = all_data['difficulty']+extraDiff['aspirant']+extraDiff['missive']\n",
    "all_data['difficulty_aspirant_embellishment'] = all_data['difficulty']+extraDiff['aspirant']+extraDiff['embellishment']\n",
    "all_data['difficulty_aspirant_missive_embellishment'] = all_data['difficulty']+extraDiff['aspirant']+extraDiff['missive']+extraDiff['embellishment']\n",
    "all_data['difficulty_gladiator'] = all_data['difficulty']+extraDiff['gladiator']\n",
    "all_data['difficulty_gladiator_missive'] = all_data['difficulty']+extraDiff['gladiator']+extraDiff['missive']\n",
    "all_data['difficulty_gladiator_embellishment'] = all_data['difficulty']+extraDiff['gladiator']+extraDiff['embellishment']\n",
    "all_data['difficulty_gladiator_missive_embellishment'] = all_data['difficulty']+extraDiff['gladiator']+extraDiff['missive']+extraDiff['embellishment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = ['', '_safetycomponent', '_missive', '_embellishment', '_safetycomponent_missive', \n",
    "             '_missive_embellishment', '_weathered', '_weathered_safetycomponent', \n",
    "             '_weathered_safetycomponent_missive', '_weathered_missive', '_weathered_embellishment',\n",
    "             '_weathered_missive_embellishment', '_runed', '_runed_safetycomponent', '_runed_safetycomponent_missive', '_runed_missive',\n",
    "             '_runed_embellishment', '_runed_missive_embellishment', '_gilded', '_gilded_safetycomponent', \n",
    "             '_gilded_missive', '_gilded_safetycomponent_missive', '_gilded_embellishment', \n",
    "             '_gilded_missive_embellishment', '_combatant', '_combatant_missive', '_combatant_embellishment', \n",
    "             '_combatant_missive_embellishment', '_aspirant', '_aspirant_missive', '_aspirant_embellishment', \n",
    "             '_aspirant_missive_embellishment', '_gladiator', '_gladiator_missive', '_gladiator_embellishment', \n",
    "             '_gladiator_missive_embellishment']\n",
    "    \n",
    "for modifier in modifiers:\n",
    "    all_data['rank1mats_outcome'+modifier] = all_data.apply(lambda row: outcomeQuality(row['skill1'], \n",
    "                                                                                       row['difficulty'+modifier], \n",
    "                                                                                       row['tag']), axis=1)\n",
    "    all_data['rank2mats_outcome'+modifier] = all_data.apply(lambda row: outcomeQuality(row['skill2'], \n",
    "                                                                                       row['difficulty'+modifier], \n",
    "                                                                                       row['tag']), axis=1)\n",
    "    all_data['rank3mats_outcome'+modifier] = all_data.apply(lambda row: outcomeQuality(row['skill3'], \n",
    "                                                                                       row['difficulty'+modifier], \n",
    "                                                                                       row['tag']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['difficulties'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82873fcd",
   "metadata": {},
   "source": [
    "# Proper Case tag field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d02ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['tag'] = all_data['tag'].apply(lambda x: x.title() if x != \"gear (pvp)\" else \"Gear (PvP)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9141c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['text formatting'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca45f9",
   "metadata": {},
   "source": [
    "# Remove pd.NA and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "all_data['character'] = all_data['character'].replace({pd.NA:None, 'None':None})\n",
    "all_data = all_data.sort_values(by=['profession', 'item'], ascending=[True, True])\n",
    "\n",
    "assert(len(all_data['character'].unique()==8) or len(all_data['character'].unique()==9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['trimming and sorting'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fd3c5",
   "metadata": {},
   "source": [
    "# File Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.to_pickle(STATIC_DIR+'items_TWW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_pickle(STATIC_DIR+'data_TWW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27664597",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['saving'] = curTime - lastTime\n",
    "lastTime = curTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_pickle(STATIC_DIR+'items_TWW.pkl')\n",
    "all_data = pd.read_pickle(STATIC_DIR+'data_TWW.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1159096",
   "metadata": {},
   "source": [
    "# Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curTime = time.time()\n",
    "times['total'] = curTime - startTime\n",
    "\n",
    "display(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc35cf",
   "metadata": {},
   "source": [
    "# Issue Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933d9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
